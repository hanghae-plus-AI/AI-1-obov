{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/obov/.cache/torch/hub/huggingface_pytorch-transformers_main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load(\n",
    "    repo_or_dir=\"huggingface/pytorch-transformers\",\n",
    "    model=\"model\",\n",
    "    pretrained_model_name_or_path=\"distilbert-base-uncased\",\n",
    ")\n",
    "model.config.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutput(last_hidden_state=tensor([[[ 0.3001,  0.5055, -0.1318,  ..., -0.4879, -0.8452,  0.2140],\n",
      "         [ 0.2331,  0.3491, -0.1390,  ..., -0.3960, -0.2859,  0.0252],\n",
      "         [ 0.2291,  0.0253, -0.0221,  ..., -0.2910, -0.0595, -0.0702],\n",
      "         [-0.1747,  0.4513,  0.1002,  ..., -0.3464, -0.2671,  0.1382],\n",
      "         [-0.1835,  0.4183,  0.2852,  ..., -0.1415, -0.1960,  0.3141],\n",
      "         [-0.2379,  0.3317,  0.3834,  ...,  0.0327, -0.0470,  0.3877]],\n",
      "\n",
      "        [[ 0.2520, -0.3201,  0.3655,  ..., -0.2526,  0.3130, -0.2502],\n",
      "         [ 0.3022, -0.2151,  0.3503,  ..., -0.1660,  0.3403, -0.3780],\n",
      "         [ 0.3166, -0.2242,  0.3420,  ..., -0.1793,  0.3316, -0.3833],\n",
      "         [ 0.3270, -0.2421,  0.3442,  ..., -0.1860,  0.3369, -0.3898],\n",
      "         [ 0.3335, -0.2635,  0.3544,  ..., -0.1930,  0.3576, -0.4066],\n",
      "         [ 0.3360, -0.2824,  0.3636,  ..., -0.2015,  0.3685, -0.4142]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor([[7592, 2057, 2097, 2393, 9611, 2115], [7592, 0, 0, 0, 0, 0]])\n",
    "output1 = model(input_ids)\n",
    "print(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.3278e-01,  4.7688e-01, -2.1987e-01,  3.7865e-01, -3.0753e-01,\n",
      "          -2.9591e-01,  1.9465e-01,  7.3193e-01, -2.5531e-01,  2.1768e-01,\n",
      "           6.8451e-02, -1.7196e-01, -2.4590e-01,  3.7573e-01, -6.7702e-01,\n",
      "           8.5401e-01, -7.2232e-01,  4.8827e-01, -4.0099e-01,  1.7213e-01,\n",
      "           2.6249e-01,  4.3922e-03,  1.3611e-01,  1.1130e-01, -5.9091e-02,\n",
      "          -2.6408e-01, -1.8209e-01,  3.6750e-01, -2.2028e-01, -1.1873e-01,\n",
      "          -4.0116e-01, -3.7263e-01,  4.7349e-01,  2.7298e-01, -3.5276e-01,\n",
      "          -5.6177e-01,  9.4463e-01, -1.3907e-01, -4.9106e-01, -4.4841e-01,\n",
      "          -4.1542e-01,  6.9512e-03,  2.1390e-01,  6.7661e-01,  6.4741e-01,\n",
      "          -3.7991e-01,  5.3262e-01,  5.3981e-01,  5.1602e-01,  5.0126e-01,\n",
      "          -2.4012e-01,  2.8672e-01,  2.8646e-01,  1.3572e-01,  3.4157e-01,\n",
      "           6.0013e-01, -7.1519e-02, -9.8793e-01, -6.5276e-02,  9.3458e-03,\n",
      "          -5.6433e-03,  1.2218e-01, -1.5343e-01, -4.3119e-01,  1.6644e-01,\n",
      "           7.7296e-02, -5.7836e-01, -3.4779e-02, -7.7342e-01, -9.5741e-02,\n",
      "          -5.7882e-01, -9.4324e-01, -9.7920e-02,  5.3947e-01, -2.8914e-01,\n",
      "           7.0634e-01, -9.3835e-01,  6.1262e-01, -2.3358e-01, -2.4597e-01,\n",
      "          -5.6405e-01,  3.7411e-01, -9.3213e-02,  5.4124e-01,  3.8772e-01,\n",
      "          -6.0483e-01, -1.9959e-01,  6.6488e-01, -7.1422e-01,  4.7875e-01,\n",
      "           7.9918e-01, -1.7156e-01,  3.9871e-01, -2.2670e-01,  2.4678e-01,\n",
      "           3.6316e-01, -3.8166e-01,  4.4479e-01, -3.3928e-01,  3.4340e-02,\n",
      "           4.6929e-01,  9.8578e-02,  2.2051e-01,  5.8123e-01, -1.8819e-01,\n",
      "          -4.0552e-01, -9.6483e-02,  1.0695e-01,  3.2171e-02,  9.9748e-01,\n",
      "           6.2905e-01, -4.9767e-01,  1.8415e-01, -2.0556e-01, -5.1503e-01,\n",
      "          -4.0648e-01,  1.7289e-01, -4.7976e-02,  2.4081e-01, -3.9884e-01,\n",
      "          -2.2197e-01, -9.0813e-01,  4.2092e-01,  2.2207e+00, -2.4099e-01,\n",
      "           2.8960e-01, -8.7275e-01, -6.1052e-02,  2.9451e-01, -4.6999e-01,\n",
      "          -2.7851e-01,  7.3843e-01,  4.7908e-01,  2.4362e-01,  4.6328e-01,\n",
      "           8.4829e-01, -1.9933e-01,  5.4406e-01, -1.3014e+00, -6.4682e-02,\n",
      "          -3.1912e-01,  2.6617e-01,  5.6714e-01, -3.1507e-01,  2.3308e-01,\n",
      "           7.7358e-01,  1.2329e-01, -2.7197e-01,  8.5274e-04,  1.1798e-01,\n",
      "           6.7170e-01,  4.0874e-01, -1.8413e-01, -5.6090e-01,  8.6830e-03,\n",
      "           2.1192e-01, -2.6241e-01,  4.9654e-01,  1.4528e-01,  3.2378e-01,\n",
      "           7.0494e-01,  2.2950e-01,  2.8783e-01,  5.5096e-01, -1.5446e-01,\n",
      "           5.2060e-01, -8.1858e-01,  5.9877e-01,  8.4772e-02,  3.5453e-01,\n",
      "          -4.9976e-01, -1.1036e-01,  9.4816e-01, -1.2770e-01,  4.8144e-03,\n",
      "           5.9858e-01,  1.0494e+00, -8.3869e-01,  6.2492e-01, -2.2617e-01,\n",
      "          -7.0819e+00,  3.0330e-01,  3.3435e-01,  5.2364e-01,  2.5206e-01,\n",
      "          -2.0102e-02,  4.3547e-01, -1.6711e-02,  8.4489e-02, -1.1164e+00,\n",
      "          -7.3400e-01,  3.3364e-01, -1.9566e-01,  1.9294e-01,  9.4360e-01,\n",
      "          -3.0379e-02,  3.5863e-01, -6.2372e-01, -9.6643e-01, -2.0147e-01,\n",
      "           1.6892e-01, -1.5303e-01,  5.0492e-01,  2.8362e-01,  1.0561e-01,\n",
      "          -1.0313e+00, -1.3512e-01, -8.9121e-01, -4.7439e-01,  1.2952e-01,\n",
      "          -1.2116e+00,  2.5540e-01,  9.3811e-01, -4.1726e-01, -4.6391e-01,\n",
      "          -4.3604e-01, -3.1466e-01, -4.9149e-01, -7.0994e-01, -2.1281e-01,\n",
      "          -2.3042e-01, -3.0582e-01, -3.3974e-01,  4.5200e-01,  9.2224e-01,\n",
      "           6.3023e-02,  2.0984e-01, -1.2987e-01,  9.8376e-01,  4.3794e-01,\n",
      "           4.9062e-01, -6.9716e-02,  1.2485e+00, -6.8067e-01, -9.7474e-01,\n",
      "           4.3173e-01, -3.7774e-01, -3.2324e-01,  9.1256e-03, -3.3873e-01,\n",
      "          -1.1080e-01, -1.0316e-01,  4.7481e-01, -8.0817e-01, -4.2851e-01,\n",
      "          -4.7015e-01, -3.0847e-01, -5.7995e-02,  3.0668e-01, -1.4986e-01,\n",
      "           3.5446e-01, -1.3998e-01,  6.5147e-01, -7.5782e-02,  4.1930e-01,\n",
      "          -4.9147e-01,  4.1743e-01,  3.7134e-01, -3.0320e-01,  3.2181e-01,\n",
      "           3.9901e-01,  2.5908e-02,  4.7360e-01, -9.1462e-02,  4.5825e-01,\n",
      "          -4.6985e-02,  5.4718e-01, -7.5617e-01, -6.1990e-01,  3.5936e-01,\n",
      "           6.4227e-02, -2.7600e-01, -3.0300e-01,  1.0649e+00, -3.4255e-01,\n",
      "          -4.3010e-01,  5.1856e-01, -1.3073e-01,  6.3728e-02,  1.8314e-01,\n",
      "          -6.4771e-01,  3.5324e-01, -1.6527e-01, -6.4423e-01, -4.0141e-01,\n",
      "          -2.3443e-01, -3.2128e-01,  4.6256e-01,  7.2185e-02, -1.3625e-01,\n",
      "          -3.4960e-01,  3.2036e-01,  9.8683e-02, -1.8233e-01, -2.5348e-01,\n",
      "           3.5503e-01,  7.9104e-01, -1.9215e-01, -2.9649e-01, -3.0750e-01,\n",
      "           2.9986e-01, -3.2699e-01, -2.0746e-01, -3.4633e-01, -4.8686e-01,\n",
      "          -1.1200e-01,  1.9465e-01, -7.7895e-01, -1.4427e+00, -1.6220e-01,\n",
      "           5.7175e-01, -6.7645e-01,  4.4367e-01,  3.1684e-01, -2.0837e-02,\n",
      "          -2.8722e-01, -7.7989e-01,  5.9106e-01, -3.1721e-01, -5.3440e-01,\n",
      "           4.1169e-01,  7.6872e-01,  3.3571e-01, -2.5259e-01,  8.9984e-02,\n",
      "           7.5186e-02, -1.1567e+00, -8.7498e-02,  1.9758e-01, -1.6802e-01,\n",
      "           3.7687e-01, -7.0507e-01,  8.0657e-01,  6.9880e-01,  2.0189e-01,\n",
      "          -9.6401e-01, -8.3881e-02,  3.1402e-02,  1.8212e-01, -6.4370e-01,\n",
      "           6.3277e-02, -6.7822e-03, -4.5020e-02,  2.5890e-01, -1.1618e-01,\n",
      "           5.3719e-02,  2.3098e-01, -3.5387e-01,  7.9569e-02,  7.7380e-02,\n",
      "          -1.2413e-01, -3.2128e-01, -1.6596e-01, -4.3991e-01,  3.5471e-02,\n",
      "          -3.7810e-01, -2.4279e-02,  9.4386e-01,  2.9695e-01,  2.1050e-01,\n",
      "           8.8363e-02, -8.2085e-01,  1.9825e-02, -1.8529e-01,  5.7194e-01,\n",
      "           5.9819e-01, -4.0232e-01, -1.0276e+00,  5.6628e-01,  5.5173e-02,\n",
      "          -3.8582e-01,  4.7170e-01, -3.8739e-01, -4.8031e-01, -2.4071e-01,\n",
      "           7.4153e-01, -8.5202e-01,  1.1746e-01, -6.2760e-01, -8.9185e-02,\n",
      "          -3.8118e-01, -5.2053e-01, -7.8240e-01, -7.9047e-01,  9.1092e-03,\n",
      "          -3.0520e-01,  6.4744e-01,  5.1876e-03, -1.0779e-01, -5.9331e-01,\n",
      "          -9.0667e-02,  6.5683e-01, -5.7897e-01, -6.8858e-01, -7.6382e-01,\n",
      "          -6.1611e-01,  1.9707e-01, -5.4188e-01,  1.1834e-01,  2.3093e-01,\n",
      "           2.1066e-01,  4.3865e-01,  1.9953e-01,  6.6048e-01,  5.1528e-01,\n",
      "          -1.2917e-01, -1.0117e-01, -5.9182e-01, -7.2583e-01,  6.3585e-01,\n",
      "           5.2067e-01,  1.8388e-01,  5.4507e-01,  2.0975e-01, -9.8231e-01,\n",
      "          -4.2666e-01, -1.4254e-02,  6.9822e-01,  5.3501e-01, -6.1925e-01,\n",
      "          -4.5706e-01, -2.6169e-01, -1.8762e-01, -8.1969e-02,  3.9884e-01,\n",
      "           1.5766e+00, -2.0570e-01,  3.4110e-01,  1.4248e-01,  7.5930e-01,\n",
      "          -1.7729e-01,  3.2732e-01,  2.4669e-01, -2.1370e-01, -8.0373e-03,\n",
      "          -2.6061e-01,  3.1184e-01, -3.6775e-01, -8.7677e-01, -8.1160e-03,\n",
      "           2.2670e-02, -4.9369e-01,  1.4290e-01,  3.3696e-01,  4.5986e-01,\n",
      "          -1.4351e-01, -4.9359e-01, -2.9476e-02, -1.4487e-02,  7.9336e-02,\n",
      "          -7.7503e-01, -4.3008e-01,  2.0814e-01,  3.3057e-01, -5.9097e-01,\n",
      "          -3.5914e-03,  3.3970e-01,  3.1172e-01, -1.3718e-01, -8.5562e-02,\n",
      "           2.7257e-01, -5.7252e-01, -3.8820e-01, -5.1594e-01,  1.3869e-02,\n",
      "          -2.1584e-01, -4.2517e-01, -1.3295e+00, -6.6343e-02, -1.0411e-01,\n",
      "           5.6951e-01,  2.9647e-01, -1.0433e+00, -2.0186e-01,  4.1123e-01,\n",
      "           1.0511e-01,  1.8431e-02, -1.4505e-01,  4.5372e-01,  2.1781e-01,\n",
      "           6.7195e-01, -4.3800e-01, -6.6747e-01,  9.8007e-01,  6.8730e-01,\n",
      "           5.6158e-02, -1.2960e-02,  5.5552e-01,  1.3972e-01, -8.6707e-01,\n",
      "           1.7784e-02, -5.0632e-02,  3.4054e-01,  2.9591e-01,  7.4653e-01,\n",
      "          -5.8405e-01,  5.0551e-01, -6.4850e-01, -7.3755e-01, -4.8670e-01,\n",
      "          -6.5693e-01,  4.3912e-01, -8.6439e-01, -1.8237e-01,  9.7355e-01,\n",
      "          -5.3958e-01,  3.5571e-01, -2.3594e-01,  2.8692e-01, -1.3527e-01,\n",
      "          -7.0171e-01,  9.3389e-02, -1.7295e-01, -7.3137e-01,  8.6528e-03,\n",
      "          -2.8037e-01, -5.6340e-01,  7.0665e-01, -5.9584e-01, -1.3252e+00,\n",
      "          -6.3976e-01, -3.9956e-01,  2.8001e-01, -2.9321e-01,  5.0364e-01,\n",
      "           7.5772e-01,  6.2114e-01, -3.9213e-01, -1.4043e+00, -2.0448e-01,\n",
      "          -4.9713e-01, -9.1905e-02, -3.1280e-01, -9.6852e-01, -2.1269e-01,\n",
      "           6.7535e-01, -6.2023e-01, -4.9019e-01, -1.5871e-01, -3.5861e-03,\n",
      "          -5.9120e-01, -6.1770e-01,  3.1561e-01, -1.7259e-01,  2.1708e-01,\n",
      "          -6.3665e-01,  2.4382e-01,  3.4848e-01,  6.8579e-01,  1.6743e-01,\n",
      "           5.4606e-01, -5.2420e-01,  1.0846e+00,  3.5043e-02, -4.1898e-01,\n",
      "           8.0807e-01,  5.3453e-01, -3.1076e-01,  8.9722e-02,  4.1955e-01,\n",
      "           6.1193e-01, -2.0973e-01, -9.2974e-01, -9.7859e-01, -3.5613e-01,\n",
      "          -5.7881e-02,  2.7632e-01, -3.8880e-01, -3.3795e-02, -1.9687e-02,\n",
      "           2.3259e-01, -1.6350e-01,  3.4147e-01, -2.6603e-01,  3.4404e-01,\n",
      "           3.3042e-01,  2.9253e-01, -6.7182e-01, -1.8843e-01,  2.3668e-01,\n",
      "          -1.7307e-01, -5.9334e-01, -4.8431e-01,  3.2325e-01,  3.4718e-01,\n",
      "          -6.3495e-01, -3.1040e-01, -6.0006e-02, -2.5719e-01,  8.7156e-02,\n",
      "          -2.4451e-01,  3.1509e-01, -5.7878e-01, -2.1001e-01, -2.0118e-01,\n",
      "           8.5778e-01, -2.5768e-01, -2.6429e-01,  4.5646e-01,  2.8665e-01,\n",
      "           2.8916e-03,  8.3988e-01,  9.1738e-02,  5.6189e-01,  5.2098e-02,\n",
      "           3.8527e-01,  1.9936e-01,  2.0803e-03,  2.2336e-02,  1.5326e+00,\n",
      "           5.8577e-01, -1.1146e-01,  3.8159e-01,  3.1689e-01,  5.0993e-01,\n",
      "          -3.3587e-01, -4.9610e-02,  3.6896e-01, -2.6975e-01,  6.5730e-01,\n",
      "           5.6478e-01,  6.3935e-01, -1.3083e+00, -9.0106e-02, -1.8553e-01,\n",
      "          -6.0267e-01, -4.7109e-01, -6.3070e-03,  8.4634e-01,  1.0492e-01,\n",
      "           2.9916e-02,  2.5402e-01,  4.6915e-01,  6.1386e-01, -5.4589e-01,\n",
      "          -2.1206e-01, -5.2365e-02,  4.6620e-01,  3.2173e-01,  3.7539e-01,\n",
      "          -1.8480e-01,  1.8836e-01,  2.1171e-01, -3.6578e-01, -4.6917e-01,\n",
      "           1.2726e+00,  7.7888e-01, -5.0083e-02, -1.9295e-01,  8.9892e-01,\n",
      "           4.5025e-01,  6.7883e-01, -4.8580e-04,  2.6707e-01, -4.7159e-01,\n",
      "           7.9137e-02,  8.9969e-01,  3.3905e-01,  7.3436e-01,  3.8886e-01,\n",
      "          -2.7650e-01,  1.1359e-01, -8.3743e-01,  5.1271e-01,  7.9191e-01,\n",
      "           8.3112e-01, -3.9177e-01,  6.5890e-01,  6.9645e-01, -2.7053e-01,\n",
      "          -6.2667e-01, -5.6852e-01, -3.3976e-01,  1.2130e+00,  5.5989e-02,\n",
      "          -2.7191e-01, -1.1647e+00,  1.4379e-01,  1.1990e-01,  5.4984e-01,\n",
      "          -1.8085e-01,  1.5759e-01, -4.0287e-01, -2.9326e-02, -4.6930e-02,\n",
      "           1.4528e-01, -8.6046e-01, -2.5317e-01, -4.8217e-01,  1.2517e-01,\n",
      "          -9.4731e-01, -2.0099e-01,  7.8632e-02,  3.9313e-01, -4.0705e-02,\n",
      "          -3.8423e-01,  9.7400e-01,  6.5247e-01, -2.2851e-01, -9.1169e-01,\n",
      "          -3.6801e-01,  2.9800e-02,  4.0566e-01, -5.6412e-01,  3.5307e-01,\n",
      "           3.5816e-01,  8.9433e-01, -4.8603e-01,  3.7126e-01, -1.5087e-01,\n",
      "          -5.3457e-01,  4.2860e-01, -5.5980e-02, -4.3353e-01,  1.1401e+00,\n",
      "           5.5662e-01, -1.8310e-01, -1.2261e-01, -1.0839e-01,  6.9506e-01,\n",
      "          -2.8646e+00,  5.5759e-01, -4.2955e-01, -3.4386e-02,  6.3143e-01,\n",
      "           2.5138e-01, -7.7283e-01, -2.6089e-01,  5.7065e-01, -6.1767e-02,\n",
      "           8.8138e-01,  2.8743e-01,  2.6038e-01, -3.8080e-01,  9.6932e-02,\n",
      "           4.8822e-01, -1.6416e-01, -1.7466e-01, -4.1960e-02,  4.3719e-01,\n",
      "           1.7726e-01, -9.0124e-02,  1.5162e-01, -1.5315e-01, -5.1124e-02,\n",
      "          -5.5323e-01, -2.2518e-01, -7.2958e-01, -2.3258e-01, -2.0655e-01,\n",
      "           1.0695e-02,  4.1962e-01,  9.9501e-01,  3.6223e-02,  2.2380e-01,\n",
      "          -5.3416e-01, -5.5806e-01, -8.3626e-01, -1.2816e-01,  6.3139e-02,\n",
      "           2.1452e-02, -8.0555e-01,  2.6840e-01, -1.2271e+00, -9.3652e-02,\n",
      "          -5.8110e-02, -7.1233e-01,  1.9466e-01]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor([[7592]])\n",
    "output2 = model(input_ids)\n",
    "print(output2.last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.3001,  0.5055, -0.1318,  ..., -0.4879, -0.8452,  0.2140],\n",
      "         [ 0.2331,  0.3491, -0.1390,  ..., -0.3960, -0.2859,  0.0252],\n",
      "         [ 0.2291,  0.0253, -0.0221,  ..., -0.2910, -0.0595, -0.0702],\n",
      "         [-0.1747,  0.4513,  0.1002,  ..., -0.3464, -0.2671,  0.1382],\n",
      "         [-0.1835,  0.4183,  0.2852,  ..., -0.1415, -0.1960,  0.3141],\n",
      "         [-0.2379,  0.3317,  0.3834,  ...,  0.0327, -0.0470,  0.3877]],\n",
      "\n",
      "        [[ 0.2328,  0.4769, -0.2199,  ..., -0.0581, -0.7123,  0.1947],\n",
      "         [ 0.3244,  0.4633, -0.2135,  ..., -0.0797, -0.7053,  0.1202],\n",
      "         [ 0.3040,  0.4531, -0.2033,  ..., -0.0923, -0.7214,  0.1124],\n",
      "         [ 0.3103,  0.4410, -0.2037,  ..., -0.0985, -0.7337,  0.1153],\n",
      "         [ 0.3089,  0.4411, -0.1998,  ..., -0.0983, -0.7324,  0.1153],\n",
      "         [ 0.3091,  0.4351, -0.1958,  ..., -0.1012, -0.7316,  0.1165]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[ 0.3001,  0.5055, -0.1318,  ..., -0.4879, -0.8452,  0.2140],\n",
      "        [ 0.2328,  0.4769, -0.2199,  ..., -0.0581, -0.7123,  0.1947]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([0.3001, 0.2328], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor([[7592, 2057, 2097, 2393, 9611, 2115], [7592, 0, 0, 0, 0, 0]])\n",
    "attention_mask = torch.tensor([[1, 1, 1, 1, 1, 1], [1, 0, 0, 0, 0, 0]])\n",
    "output3 = model(input_ids, attention_mask=attention_mask)\n",
    "print(output3.last_hidden_state)\n",
    "print(output3.last_hidden_state[:, 0])\n",
    "print(output3.last_hidden_state[:, 0][..., 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week3-iJowBwG1-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
